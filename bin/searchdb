#!/usr/bin/env python3
"""
Extracts details about each document and adds them to a database.
"""

import pathlib
import sqlite3
import sys
import bs4

def get_summary(soup):
    """Extract a summary from the HTML content."""
    summary = ""
    p_elts = soup.find_all("p", class_=False)
    for p in p_elts:
        p = p.text
        # If the body isn't empty and longer than 50 characters (arbitrary)
        if p.strip() and len(p) > 50:
            # Limit summary to 250 characters (including truncation)
            summary = p.strip()[0:247]

            # Replace newlines to format query string
            summary = summary.replace("\n", " ")

            # Truncate endings
            summary = summary + "..."
            break

    return summary


def build_search_db(input_dir, output_db_path):
    """
    Build the search database from inverted index files.

    Args:
        input_dir (pathlib.Path): Directory containing inverted index files.
        output_db_path (pathlib.Path): Path to the output SQLite database.
    """
    conn = sqlite3.connect(output_db_path)
    c = conn.cursor()

    # Create table
    c.execute("""
        CREATE TABLE IF NOT EXISTS documents (
            docid INTEGER PRIMARY KEY,
            title VARCHAR(150),
            summary VARCHAR(250),
            url VARCHAR(150)
        )
    """)

    # Process each inverted index file
    for index_file in input_dir.glob("*.html"):
        with index_file.open("r") as f:
            # for line in f:
                # parts = line.strip().split('\t')
                # if len(parts) < 4:
                #     continue
                # doc_id, title, url, snippet = parts[0], parts[1], parts[2], parts[3]
            soup = bs4.BeautifulSoup(f.read(), "html.parser")
            docid = int(soup.find("meta", attrs={"eecs485_docid": True}).get("eecs485_docid"))
            title = soup.find("title").get_text()[:150]
            summary = get_summary(soup)
            url = soup.find("meta", attrs={"eecs485_url": True}).get("eecs485_url")[:150]
            soup.find("meta", attrs={"eecs485_url": True}).get("eecs485_url")
            
            c.execute("""
                INSERT OR REPLACE INTO documents (docid, title, summary, url)
                VALUES (?, ?, ?, ?)
            """, (docid, title, summary, url))

    conn.commit()
    conn.close()


def main():
    """Main function to run the searchdb script."""

    # set paths
    input_dir = pathlib.Path("inverted_index/crawl/")
    output_dir = pathlib.Path("var/search.sqlite3")

    # create output directory if it doesn't exist
    output_dir.parent.mkdir(parents=True, exist_ok=True)

    # remove existing database if it exists
    if output_dir.exists():
        output_dir.unlink()

    build_search_db(input_dir, output_dir)

if __name__ == "__main__":
    main()